
from dagster import AssetIn, asset, AssetKey, AssetExecutionContext, resource
import sys
import os
os.environ["SPARK_VERSION"] = "3.5" 
os.environ["PYSPARK_PYTHON"] = "C:/Users/Rania/Documents/PFE/refs_data_quality_pipeline/venv/Scripts/python.exe"
os.environ["PYSPARK_DRIVER_PYTHON"] = "C:/Users/Rania/Documents/PFE/refs_data_quality_pipeline/venv/Scripts/python.exe"
from dagster_dbt import dbt_assets,DbtCliResource
from .project import ref_dq
from dagster import AssetExecutionContext
from pyspark.sql import SparkSession


sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

# from deequ.preprocessing import import_data, preprocess_level_names,data_checks,shorten_hierarchy,data_exploration
from scripts.distilBERT_model import bert
from scripts.merge_problems import process_problems
from scripts.data_scores_evals import data_report_processing
from scripts.locations_preprocessing import preprocess_continents, assign_country_to_correct_continent, correcting_hierarchies, add_parent_column, assign_level_numbers, merging, adding_official_level_names


from deequ.quality_validation import import_data, deequ_quality_check

@resource
def spark_session():
    spark = SparkSession.builder.appName("deequ").config("spark.jars.packages", "com.amazon.deequ:deequ:2.0.9-spark-3.5") \
        .getOrCreate()
    yield spark
    spark.stop()

@asset(description="Loads data from a CSV file into a DataFrame.",
       required_resource_keys={"spark_session"})
def import_data_asset(context):
    spark_session = context.resources.spark_session
    df = import_data(spark_session)
    return df.toPandas()

@asset(description="Explores the data using Deequ's analysis tools.", deps=["adding_official_level_names_asset"],
       required_resource_keys={"spark_session"})
def deequ_data_validation(context,adding_official_level_names_asset):
    df,missing_rows = adding_official_level_names_asset
    spark_session = context.resources.spark_session
    result, problems = deequ_quality_check(spark_session, df)

    # Convert each Spark DataFrame in problems dict to pandas
    problems_pandas = {k: v.toPandas() for k, v in problems.items()}

    return result.toPandas(), problems_pandas

@asset(description="Processing the report generated by Deequ.")
def processing_deequ_report(deequ_data_validation):
    result, _ = deequ_data_validation
    return data_report_processing(result)
       
@asset(description="Processing the problematic rows.")
def processing_problem_rows(deequ_data_validation, bert_model, merging_processed_data_asset):
    _, problems = deequ_data_validation
    duplicates = bert_model
    _, missing_rows = merging_processed_data_asset
    return process_problems(problems, duplicates, missing_rows)
       
@asset(description="Preprocess Continents in the data.",)
def preprocess_continents_asset():
    return preprocess_continents()

@asset(description="Iterates through country rows and assigns them to the correct continent.",)
def assign_country_to_correct_continent_asset(preprocess_continents_asset):
    continents, df = preprocess_continents_asset
    return assign_country_to_correct_continent(continents, df)

@asset(description="Correcting the countries' hierarchies.",)
def correcting_hierarchies_asset(assign_country_to_correct_continent_asset):
    df_countries, df, continents = assign_country_to_correct_continent_asset
    return correcting_hierarchies(continents, df_countries, df)

@asset(description="Adding parent column where each subregion is assigned to a country.",)
def add_parent_column_asset(correcting_hierarchies_asset):
    countries_with_corrected_hierarchies,continents, df = correcting_hierarchies_asset
    return add_parent_column(countries_with_corrected_hierarchies,continents, df)

@asset(description="Adding level number column and assigning each row to a level.",)
def assign_level_numbers_asset(add_parent_column_asset):
    df, countries_with_corrected_hierarchies, continents = add_parent_column_asset
    return assign_level_numbers(df, countries_with_corrected_hierarchies, continents)

@asset(description="Merging processed data.",)
def merging_processed_data_asset(assign_level_numbers_asset):
    df, countries_with_corrected_hierarchies, continents = assign_level_numbers_asset
    return merging(df, countries_with_corrected_hierarchies, continents)

@asset(description="Adding official admin level names.",)
def adding_official_level_names_asset(merging_processed_data_asset):
    locations_processed, missing_in_locations = merging_processed_data_asset
    return adding_official_level_names(locations_processed), missing_in_locations

@asset(description="Applying the distilBERT model the data.")
def bert_model(adding_official_level_names_asset):
    df, missing_in_locations = adding_official_level_names_asset
    return bert(df)

# -- dbt assets --
@dbt_assets(manifest=ref_dq.manifest_path)
def ref_dq_dbt_assets(context: AssetExecutionContext, dbt: DbtCliResource):
    yield from dbt.cli(["build"], context=context).stream()